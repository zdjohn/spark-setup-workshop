{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JOB 1\n",
    "\n",
    "we will look into:\n",
    "\n",
    "    - loading data from s3\n",
    "    - analyse and gettting dataframe stats by using `describe`\n",
    "    - group by, agg operations\n",
    "    - filtering, selecting cleaning data into desired data features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import findspark; findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import configparser\n",
    "from os import environ, listdir, path\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from src.commons import utils\n",
    "from src.amazon_reviews import etl, job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMR 6.10\n",
    "environ['PYSPARK_SUBMIT_ARGS'] = \"--packages=com.amazonaws:aws-java-sdk:1.11.900,org.apache.hadoop:hadoop-aws:3.2.0 pyspark-shell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "environ['DEBUG'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(path.expanduser(\"~/.aws/credentials\"))\n",
    "access_id = config.get('default', \"aws_access_key_id\") \n",
    "access_key = config.get('default', \"aws_secret_access_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIG_MUCSIC_FILE_PATH ='../data/part-00009-495c48e6-96d6-4650-aa65-3c36a3516ddd.c000.snappy.parquet'\n",
    "DIG_MUSIC_S3 = \"s3a://amazon-reviews-pds/parquet/product_category=Digital_Music_Purchase/*.snappy.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session, logger= utils.start_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://hadoop.apache.org/docs/current3/hadoop-aws/tools/hadoop-aws/s3n.html#How_to_migrate_to_to_the_S3A_client\n",
    "hadoop_conf=session._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3a.access.key\", access_id)\n",
    "hadoop_conf.set(\"fs.s3a.secret.key\", access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run everything together job.run(session, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_munisc_df = utils.extract_parquet_data(session,DIG_MUSIC_S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_parent: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: string (nullable = true)\n",
      " |-- verified_purchase: string (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "digital_munisc_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aggregate following metrics by customer_id: \n",
    "- total products count\n",
    "- distinct product count\n",
    "- distinct parent product\n",
    "- review counts\n",
    "- purchase/(review) rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_agg_df = etl.to_stats_aggregation(digital_munisc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- products: long (nullable = false)\n",
      " |-- products_distinct: long (nullable = false)\n",
      " |-- pp_counts: long (nullable = false)\n",
      " |-- reviews: long (nullable = false)\n",
      " |-- verified_purchase: long (nullable = false)\n",
      " |-- purchase_rate: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchase_agg_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore and analyse the digital music stats using describe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary| products_distinct|     purchase_rate|\n",
      "+-------+------------------+------------------+\n",
      "|  count|            841870|            841870|\n",
      "|   mean|2.0718056231959805|0.6784817806876001|\n",
      "| stddev| 5.917138532090482|0.4465739418824318|\n",
      "|    min|                 1|               0.0|\n",
      "|    max|              1907|               1.0|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "music_purchase_agg_stats = purchase_agg_df.describe(['products_distinct', 'purchase_rate'])\n",
    "music_purchase_agg_stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above stats, we see in average, customer reviews 2 albumns. Most customers reviews the product based on confirmed purchase.\n",
    "Majority of the customers reviewed only 1 albumn, but there are customers (likely bots) reviewed 1907 albumns.\n",
    "\n",
    "In order to train our model properly. Users whom only reviewed a single product are deemed to be too sparse. we want to exclude those data points from traning.\n",
    "\n",
    "While user who reviewed over thousands of products, are likely to be a bot, those records could skew graph struscutre, which leads to poor results. Subsequently, we want to remove reviews from those costomers too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean up the review data\n",
    "\n",
    "remove sparse data points, as well as \"over active customers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get customer_ids based on their distinct product purchase (minimal 3, and maximum 50, are arbitrary numbers)\n",
    "dense_customer_ids_df = etl.to_dense_user_ids(purchase_agg_df, 3, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dense_customer_ids_df.printSchematSchematSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter review records by customer_ids\n",
    "filtered_review_df = etl.to_dense_reviews(digital_munisc_df, dense_customer_ids_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## review physical excution plan before action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(4) Project [customer_id#1, marketplace#0, review_id#2, product_id#3, product_parent#4, product_title#5, star_rating#6, helpful_votes#7, total_votes#8, vine#9, verified_purchase#10, review_headline#11, review_body#12, review_date#13, year#14]\n",
      "+- *(4) BroadcastHashJoin [customer_id#1], [customer_id#232], Inner, BuildRight\n",
      "   :- *(4) Project [marketplace#0, customer_id#1, review_id#2, product_id#3, product_parent#4, product_title#5, star_rating#6, helpful_votes#7, total_votes#8, vine#9, verified_purchase#10, review_headline#11, review_body#12, review_date#13, year#14]\n",
      "   :  +- *(4) Filter isnotnull(customer_id#1)\n",
      "   :     +- *(4) ColumnarToRow\n",
      "   :        +- FileScan parquet [marketplace#0,customer_id#1,review_id#2,product_id#3,product_parent#4,product_title#5,star_rating#6,helpful_votes#7,total_votes#8,vine#9,verified_purchase#10,review_headline#11,review_body#12,review_date#13,year#14] Batched: true, DataFilters: [isnotnull(customer_id#1)], Format: Parquet, Location: InMemoryFileIndex[s3a://amazon-reviews-pds/parquet/product_category=Digital_Music_Purchase/part-0..., PartitionFilters: [], PushedFilters: [IsNotNull(customer_id)], ReadSchema: struct<marketplace:string,customer_id:string,review_id:string,product_id:string,product_parent:st...\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true])), [id=#190]\n",
      "      +- *(3) HashAggregate(keys=[customer_id#232], functions=[])\n",
      "         +- *(3) HashAggregate(keys=[customer_id#232], functions=[])\n",
      "            +- *(3) Project [customer_id#232]\n",
      "               +- *(3) Filter ((products_distinct#47L >= 3) AND (products_distinct#47L <= 50))\n",
      "                  +- *(3) HashAggregate(keys=[customer_id#232], functions=[count(if ((gid#261 = 1)) `product_id`#262 else null)])\n",
      "                     +- Exchange hashpartitioning(customer_id#232, 2), true, [id=#182]\n",
      "                        +- *(2) HashAggregate(keys=[customer_id#232], functions=[partial_count(if ((gid#261 = 1)) `product_id`#262 else null)])\n",
      "                           +- *(2) HashAggregate(keys=[customer_id#232, `product_id`#262, `product_parent`#263, gid#261], functions=[])\n",
      "                              +- Exchange hashpartitioning(customer_id#232, `product_id`#262, `product_parent`#263, gid#261, 2), true, [id=#177]\n",
      "                                 +- *(1) HashAggregate(keys=[customer_id#232, `product_id`#262, `product_parent`#263, gid#261], functions=[])\n",
      "                                    +- *(1) Filter isnotnull(customer_id#232)\n",
      "                                       +- *(1) Expand [ArrayBuffer(customer_id#232, null, null, 0), ArrayBuffer(customer_id#232, product_id#234, null, 1), ArrayBuffer(customer_id#232, null, product_parent#235, 2)], [customer_id#232, `product_id`#262, `product_parent`#263, gid#261]\n",
      "                                          +- *(1) ColumnarToRow\n",
      "                                             +- FileScan parquet [customer_id#232,product_id#234,product_parent#235] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex[s3a://amazon-reviews-pds/parquet/product_category=Digital_Music_Purchase/part-0..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<customer_id:string,product_id:string,product_parent:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_review_df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save final data frame to target S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util.load_data_to_s3(filtered_review_df,'target_s3_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit job from your local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run command `tox -e pack`\n",
    "releasable artifact will be generated inside `./dist` folder. \n",
    "```\n",
    "dist/\n",
    "  ├── dist_files.zip\n",
    "  └── main.py\n",
    "```\n",
    "\n",
    "step into `dist` folder involke `spark submit`:\n",
    "\n",
    "```\n",
    "$: spark-submit \\\n",
    "    --master local[3] \\\n",
    "    --deploy-mode client \\\n",
    "    --packages=com.amazonaws:aws-java-sdk:1.11.900,org.apache.hadoop:hadoop-aws:3.2.0 \\\n",
    "    --py-files ./dist_files.zip \\\n",
    "    main.py --job=review --category=Digital_Music_Purchase --local_run=1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-sample",
   "language": "python",
   "name": "pyspark-sample"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
