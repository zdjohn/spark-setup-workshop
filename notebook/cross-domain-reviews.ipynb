{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import findspark; findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import configparser\n",
    "from os import environ, listdir, path\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "from src.commons import utils\n",
    "from src.cross_domain_reviews import etl\n",
    "from src.amazon_reviews.etl import to_stats_aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMR 6.10, as spark is based on JVM, version number matters\n",
    "environ['PYSPARK_SUBMIT_ARGS'] = \"--packages=com.amazonaws:aws-java-sdk:1.11.900,org.apache.hadoop:hadoop-aws:3.2.0 pyspark-shell\"\n",
    "environ['DEBUG'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_credential(session):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(path.expanduser(\"~/.aws/credentials\"))\n",
    "    access_id = config.get('default', \"aws_access_key_id\") \n",
    "    access_key = config.get('default', \"aws_secret_access_key\")\n",
    "    hadoop_conf=session._jsc.hadoopConfiguration()\n",
    "    hadoop_conf.set(\"fs.s3a.access.key\", access_id)\n",
    "    hadoop_conf.set(\"fs.s3a.secret.key\", access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "session, logger= utils.start_spark()\n",
    "s3_credential(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read the cleaned review datasets from S3, which is carried out in `amazon_reviews` job. (see source code in https://github.com/zdjohn/spark-setup-workshop/tree/master/src/amazon_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df = utils.extract_parquet_data(session, etl.DIG_MUSIC)\n",
    "video_df = utils.extract_parquet_data(session, etl.DIG_VIDEO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_parent: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: string (nullable = true)\n",
      " |-- verified_purchase: string (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "music_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_parent: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: string (nullable = true)\n",
      " |-- verified_purchase: string (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "video_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|users_count|items_count|\n",
      "+-----------+-----------+\n",
      "|     144240|     401484|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "music_df.agg(\n",
    "    F.countDistinct('customer_id').alias('users_count')\n",
    "    , F.countDistinct('product_id').alias('items_count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|users_count|items_count|\n",
      "+-----------+-----------+\n",
      "|     501158|     127873|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "video_df.agg(\n",
    "    F.countDistinct('customer_id').alias('users_count')\n",
    "    , F.countDistinct('product_id').alias('items_count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make video recommendations based on the user-item interaction information we learned from music. \n",
    "(google \"transfer learning\" if you like to know more) \n",
    "\n",
    "as a result, we need to find overlapping users who purchased both video and music product for model to learn the corelation between `video` and `music` domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20582"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_corss_reviews = etl.to_overlapping_customers(music_df, video_df)\n",
    "music_corss_reviews.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see there are **20582** customers out of (144240 music product customer, 501158 video customer) have done shopping on both amazon music and video products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|count(product_id)|\n",
      "+-----------------+\n",
      "|            96198|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corss_music_products = etl.to_overlapping_reviews(music_df,music_corss_reviews)\n",
    "corss_music_products.agg(F.countDistinct('product_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|count(product_id)|\n",
      "+-----------------+\n",
      "|            41764|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corss_video_products = etl.to_overlapping_reviews(video_df,music_corss_reviews)\n",
    "corss_video_products.agg(F.countDistinct('product_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_corss_reviews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-sample",
   "language": "python",
   "name": "pyspark-sample"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
